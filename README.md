ðŸŒ ë¹„ì²´ê³„ì  ìœ„í—˜ ë¶„ì„ Streamlit ì•± (ë°°í¬ìš©)
import streamlit as st import requests import re import pandas as pd import datetime import plotly.express as px from transformers import BertTokenizer, BertForSequenceClassification, pipeline

ìœ„í—˜ í‚¤ì›Œë“œ ì •ì˜ (í•œê¸€ + ì˜ë¬¸)
def get_risk_keywords(): return { # í•œê¸€ "ì¹¨ê³µ": 1.5, "ì „ìŸ": 1.4, "ë¹„íŒ": 1.2, "ë…¼ìŸ": 1.3, "ì œ3ì°¨ ì„¸ê³„ëŒ€ì „": 1.6, "ë¶„ì—´": 1.5, "ìœ„í˜‘": 1.4, "í›¼ì†": 1.6, "ì‹¤ìˆ˜": 1.2, "ë¶ˆë§Œ": 1.3, "ìœ„ê¸°": 1.4, "ìƒí™œë¹„": 1.1, "ë²”ì£„": 1.2, "ë¶ˆì•ˆê°": 1.3, "ê´€ì„¸": 1.3, "í•©ë³‘": 1.5, # ì˜ì–´ "recession": 1.5, "misleading": 1.3, "contracted": 1.4, "discontent": 1.3, "blamed": 1.1, "disrupted": 1.5, "scorn": 1.2, "failed": 1.6, "shortages": 1.3, "war": 1.7, "tariffs": 1.4, "levies": 1.2, }

ê¸ì • í‚¤ì›Œë“œ ê°ì ìš©
POSITIVE_KEYWORDS = { "í‰í™”": -0.8, "ë²ˆì˜": -0.6, "ìž¬ê±´": -0.5, "ì„±ìž¥": -0.4, "í˜‘ì •": -0.3, "íŒŒíŠ¸ë„ˆì‹­": -0.3, "ìœ ì¹˜": -0.4, "íšŒë³µ": -0.5, "ê¸°íšŒ": -0.4 }

KoBERT ë¡œë“œ
@st.cache_resource def load_sentiment_model(): tokenizer = BertTokenizer.from_pretrained('monologg/kobert') model = BertForSequenceClassification.from_pretrained('beomi/kcbert-base', num_labels=3) return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

ì ìˆ˜ ê³„ì‚°
def calculate_risk_score(text, keywords): text_lower = text.lower() score = 0 for word, weight in keywords.items(): count = len(re.findall(re.escape(word), text)) score += weight * count return score

def kobert_sentiment(pipeline, text): result = pipeline(text[:512])[0] label = result['label'] score = result['score'] if label == 'LABEL_0': return -score elif label == 'LABEL_2': return score return 0

UI ì‹œìž‘
st.set_page_config(page_title="Unsystematic Risk Analyzer", layout="wide") st.title("ðŸ“‰ ë‰´ìŠ¤ ê¸°ë°˜ ë¹„ì²´ê³„ì  ìœ„í—˜ ë¶„ì„ê¸°")

keyword = st.text_input("ðŸ” ë‰´ìŠ¤ í‚¤ì›Œë“œ", "ì•„ë¥´í—¨í‹°ë‚˜ ì •ì¹˜ ë¶ˆì•ˆ") api_key = st.text_input("ðŸ”‘ GNews API Key", type="password") custom_article = st.text_area("âœï¸ ë¶„ì„í•  ê¸°ì‚¬ í…ìŠ¤íŠ¸ ì§ì ‘ ìž…ë ¥ (ì„ íƒ)", height=300)

ë¶„ì„ íŠ¸ë¦¬ê±°
if st.button("ðŸš€ ë¶„ì„ ì‹œìž‘"): with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."): nlp = load_sentiment_model()

if custom_article.strip():
    articles = [custom_article.strip()]
else:
    url = f"https://gnews.io/api/v4/search?q={keyword}&lang=ko&token={api_key}"
    r = requests.get(url)
    articles = [a['title'] + ' ' + (a['description'] or '') for a in r.json().get('articles', [])]

if not articles:
    st.warning("ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    rows = []
    risk_dict = get_risk_keywords()
    for t in articles:
        base_score = calculate_risk_score(t, risk_dict)
        bonus = calculate_risk_score(t, POSITIVE_KEYWORDS)
        final_score = base_score + bonus
        polarity = kobert_sentiment(nlp, t)
        score = round(final_score * (1 - polarity), 2)
        rows.append({"í…ìŠ¤íŠ¸": t, "ìœ„í—˜ ì ìˆ˜": final_score, "ê°ì„± ì ìˆ˜": round(polarity, 2), "ìµœì¢… ìœ„í—˜ ì§€ìˆ˜": score,
                     "ì‹œê°„": datetime.datetime.now()})

    df = pd.DataFrame(rows)
    st.success(f"ì´ {len(df)}ê°œ ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ!")
    st.dataframe(df.sort_values("ìµœì¢… ìœ„í—˜ ì§€ìˆ˜", ascending=False))

    # ì‹œê°í™”
    st.subheader("ðŸ“Š ì‹œê°í™” ê²°ê³¼")
    st.plotly_chart(px.line(df, x="ì‹œê°„", y="ìµœì¢… ìœ„í—˜ ì§€ìˆ˜", title="ì‹œê°„ë³„ ìœ„í—˜ ì¶”ì„¸"))
    st.plotly_chart(px.histogram(df, x="ìµœì¢… ìœ„í—˜ ì§€ìˆ˜", nbins=15, title="ìœ„í—˜ ë¶„í¬"))
    st.plotly_chart(px.scatter(df, x="ê°ì„± ì ìˆ˜", y="ìœ„í—˜ ì ìˆ˜", color="ìµœì¢… ìœ„í—˜ ì§€ìˆ˜", size="ìµœì¢… ìœ„í—˜ ì§€ìˆ˜",
                               hover_data=["í…ìŠ¤íŠ¸"], title="ê°ì„± vs ìœ„í—˜ ì ìˆ˜ ì‚°ì ë„"))

    top5 = df.sort_values("ìµœì¢… ìœ„í—˜ ì§€ìˆ˜", ascending=False).head(5)
    st.subheader("ðŸ”¥ ê³ ìœ„í—˜ ê¸°ì‚¬ Top 5")
    for i, row in top5.iterrows():
        st.markdown(f"**{i+1}. ìœ„í—˜ë„: {row['ìµœì¢… ìœ„í—˜ ì§€ìˆ˜']} / ê°ì„±: {row['ê°ì„± ì ìˆ˜']}**")
        st.caption(row['í…ìŠ¤íŠ¸'][:400] + ("..." if len(row['í…ìŠ¤íŠ¸']) > 400 else ""))

    st.download_button("ðŸ“¥ CSV ë‹¤ìš´ë¡œë“œ", df.to_csv(index=False).encode(), "risk_analysis.csv", "text/csv")
